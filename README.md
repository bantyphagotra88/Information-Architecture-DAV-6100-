# Infromation-Architecture-DAV-6100-

# Part 1 
..I used silinium to extracted info about this website 'https://www.charitiesnys.com/RegistrySearch/search_charities.jsp'
..In the first part of my assignment we just extracted a list of charaties from the first page of search as well as also created the S3 bucket  using Python script
..I used pandas to  create dataframe from the search results i found on the first page and converted into .csv file.
..Later we uploaded the .csv file into S3 Bucket. I also made sure that .csv file is created succesfully into my AWS S3 Bucket. The Date and time was also recorded when the file was created succesfully into S3 Bucket.

# Part 2
I used silinium to extracted info about this website 'https://www.charitiesnys.com/RegistrySearch/search_charities.jsp' just like the Part 1
..In this part I used while loop that help me loop to the seventh page of search which helped me extract 100 results and then created S3 Bucket using python script
-- I used pandas o create dataframe from the search results which was 100 this time around  and coverted them into the .csv file.
.. At the end we uploaded the .csv file into S3 Bucket. I also made sure that .csv file is created succesfully into my AWS S3 Bucket. The Date and time was also recorded when the file was created succesfully into S3 Bucket
